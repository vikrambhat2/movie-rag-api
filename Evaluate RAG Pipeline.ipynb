{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a6aacb",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the functionality and evaluation of the **Movie RAG API**, a natural language movie query system that combines **structured database retrieval** with **LLM-powered response generation**. The system supports both **traditional RAG**—where queries are controlled and predictable—and **agentic RAG**, which uses autonomous SQL generation via LangChain agents for more complex analytical questions. Users can ask questions like “Recommend action movies from 2015” and receive conversational, data-backed responses from the TMDB dataset.\n",
    "\n",
    "The notebook covers the full pipeline: initializing the database, parsing queries, retrieving relevant movies, generating responses with an LLM (Ollama), and evaluating the system for accuracy, retrieval quality, response relevance, latency, and agent capabilities. Edge cases and robustness checks are also included to ensure safe and reliable operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0489b7",
   "metadata": {},
   "source": [
    "### Setup and Initialization  \n",
    "Import necessary modules, verify the `movies.db` file exists, and initialize the `MovieDB` connection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bee4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database exists: True\n",
      "Database path: /Users/vikrambhat/Documents/movie-rag-api/data/movies.db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from app.database import MovieDB\n",
    "from app.query_processor import parse_query\n",
    "from app.llm_service import generate_response\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Verify database exists\n",
    "import os\n",
    "db_path = \"data/movies.db\"\n",
    "print(f\"Database exists: {os.path.exists(db_path)}\")\n",
    "print(f\"Database path: {os.path.abspath(db_path)}\")\n",
    "\n",
    "db = MovieDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5e4c9",
   "metadata": {},
   "source": [
    "### Test Database Queries  \n",
    "Run a series of checks to validate database functionality — search by title, genre, and year, apply combined filters, and retrieve top-rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb2428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Database Tests ===\n",
      "\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND title LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%inception%', 5]\n",
      "Search 'inception': 1 results\n",
      "  → Inception (2010.0)\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 3]\n",
      "\n",
      "Action movies: 3 results\n",
      "  → The Dark Knight - 8.2/10\n",
      "  → The Empire Strikes Back - 8.2/10\n",
      "  → Seven Samurai - 8.2/10\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, 2015, 5]\n",
      "\n",
      "Movies from 2015: 5 results\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%science fiction%', 2015, 3]\n",
      "\n",
      "Sci-fi from 2015: 3 results\n",
      "\n",
      "Top rated movies:\n",
      "  → The Shawshank Redemption - 8.5/10\n",
      "  → The Godfather - 8.4/10\n",
      "  → Fight Club - 8.3/10\n",
      "  → Pulp Fiction - 8.3/10\n",
      "  → Schindler's List - 8.3/10\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Test Database Queries\n",
    "\n",
    "print(\"=== Database Tests ===\\n\")\n",
    "\n",
    "# Test 1: Search by title\n",
    "movies = db.search(title=\"inception\")\n",
    "print(f\"Search 'inception': {len(movies)} results\")\n",
    "if movies:\n",
    "    print(f\"  → {movies[0]['title']} ({movies[0]['year']})\")\n",
    "\n",
    "# Test 2: Search by genre\n",
    "action = db.search(genre=\"action\", limit=3)\n",
    "print(f\"\\nAction movies: {len(action)} results\")\n",
    "for m in action:\n",
    "    print(f\"  → {m['title']} - {m['vote_average']}/10\")\n",
    "\n",
    "# Test 3: Search by year\n",
    "movies_2015 = db.search(year=2015, limit=5)\n",
    "print(f\"\\nMovies from 2015: {len(movies_2015)} results\")\n",
    "\n",
    "# Test 4: Combined filters\n",
    "sci_fi_2015 = db.search(genre=\"science fiction\", year=2015, limit=3)\n",
    "print(f\"\\nSci-fi from 2015: {len(sci_fi_2015)} results\")\n",
    "\n",
    "# Test 5: Top rated\n",
    "top = db.get_top_rated(limit=5)\n",
    "print(f\"\\nTop rated movies:\")\n",
    "for m in top:\n",
    "    print(f\"  → {m['title']} - {m['vote_average']}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59236ea3",
   "metadata": {},
   "source": [
    "\n",
    "### Test Query Processor  \n",
    "Evaluate the `parse_query` function to ensure it correctly extracts intent, genre, year, and keywords from natural language movie-related queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98179ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query Processor Tests ===\n",
      "\n",
      "Query: Recommend action movies from 2015\n",
      "  Intent: recommend\n",
      "  Genre: action\n",
      "  Year: 2015\n",
      "  Keywords: None\n",
      "\n",
      "Query: Tell me about Inception\n",
      "  Intent: describe\n",
      "  Genre: None\n",
      "  Year: None\n",
      "  Keywords: inception\n",
      "\n",
      "Query: What are the best movies?\n",
      "  Intent: top_rated\n",
      "  Genre: None\n",
      "  Year: None\n",
      "  Keywords: are ?\n",
      "\n",
      "Query: Show me comedy films\n",
      "  Intent: search\n",
      "  Genre: comedy\n",
      "  Year: None\n",
      "  Keywords: None\n",
      "\n",
      "Query: Find sci-fi movies from 2010\n",
      "  Intent: search\n",
      "  Genre: science fiction\n",
      "  Year: 2010\n",
      "  Keywords: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Test Query Processor\n",
    "\n",
    "print(\"=== Query Processor Tests ===\\n\")\n",
    "\n",
    "test_queries = [\n",
    "    \"Recommend action movies from 2015\",\n",
    "    \"Tell me about Inception\",\n",
    "    \"What are the best movies?\",\n",
    "    \"Show me comedy films\",\n",
    "    \"Find sci-fi movies from 2010\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    result = parse_query(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"  Intent: {result['intent']}\")\n",
    "    print(f\"  Genre: {result['genre']}\")\n",
    "    print(f\"  Year: {result['year']}\")\n",
    "    print(f\"  Keywords: {result['keywords']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d25977",
   "metadata": {},
   "source": [
    "### Test LLM Service  \n",
    "Validate the `generate_response` function by passing a user query and retrieved movie data to ensure the LLM produces coherent, context-aware recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a5c8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Service Tests ===\n",
      "\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 2015, 3]\n",
      "Question: Recommend action movies from 2015\n",
      "\n",
      "Movies retrieved: 3\n",
      "  - Baahubali: The Beginning\n",
      "  - Avengers: Age of Ultron\n",
      "  - Furious 7\n",
      "\n",
      "LLM Answer:\n",
      "If you're looking for action-packed thrill rides from 2015, I'd definitely recommend checking out Avengers: Age of Ultron and Furious 7! Both movies are high-octane blockbusters that deliver non-stop excitement with impressive action sequences and thrilling plot twists. Baahubali: The Beginning also has its fair share of intense action scenes, so if you're in the mood for something a bit more epic, it's worth giving that a try as well!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Test LLM Service\n",
    "\n",
    "print(\"=== LLM Service Tests ===\\n\")\n",
    "\n",
    "# Get some movies\n",
    "movies = db.search(genre=\"action\", year=2015, limit=3)\n",
    "\n",
    "question = \"Recommend action movies from 2015\"\n",
    "answer = generate_response(question, movies, intent='recommend')\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"\\nMovies retrieved: {len(movies)}\")\n",
    "for m in movies:\n",
    "    print(f\"  - {m['title']}\")\n",
    "\n",
    "print(f\"\\nLLM Answer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82888bcd",
   "metadata": {},
   "source": [
    "### End-to-End Pipeline Test  \n",
    "Run full workflow validation — parse user queries, retrieve matching movies from the database, and generate LLM-based responses to confirm the complete system functions cohesively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a7203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== End-to-End Pipeline Tests ===\n",
      "\n",
      "Query: Tell me about The Matrix\n",
      "  Parsed: {'intent': 'describe', 'genre': None, 'year': None, 'keywords': 'matrix'}\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND title LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%matrix%', 5]\n",
      "  Found: 3 movies\n",
      "  Answer: So, you want to know about The Matrix? Well, it's an action-packed sci-fi movie set in the 22nd century where a computer hacker joins a group of rebel...\n",
      "\n",
      "Query: Recommend comedy movies from 2010\n",
      "  Parsed: {'intent': 'recommend', 'genre': 'comedy', 'year': 2010, 'keywords': None}\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%comedy%', 2010, 5]\n",
      "  Found: 5 movies\n",
      "  Answer: If you're in the mood for some laughs, I've got just the ticket! From your list, I'd recommend checking out \"Toy Story 3\", \"Tucker and Dale vs Evil\", ...\n",
      "\n",
      "Query: What are the best sci-fi films?\n",
      "  Parsed: {'intent': 'top_rated', 'genre': 'science fiction', 'year': None, 'keywords': 'are ?'}\n",
      "  Found: 5 movies\n",
      "  Answer: Sorry to disappoint you, but none of the movies we have data on are strictly sci-fi films! However, if you're looking for highly rated movies that mig...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: End-to-End Pipeline Test\n",
    "\n",
    "print(\"=== End-to-End Pipeline Tests ===\\n\")\n",
    "\n",
    "def test_pipeline(query):\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    # Parse\n",
    "    query_info = parse_query(query)\n",
    "    print(f\"  Parsed: {query_info}\")\n",
    "    \n",
    "    # Search\n",
    "    if query_info['intent'] == 'top_rated':\n",
    "        movies = db.get_top_rated(limit=5)\n",
    "    else:\n",
    "        movies = db.search(\n",
    "            title=query_info.get('keywords'),\n",
    "            genre=query_info.get('genre'),\n",
    "            year=query_info.get('year'),\n",
    "            limit=5\n",
    "        )\n",
    "    print(f\"  Found: {len(movies)} movies\")\n",
    "    \n",
    "    # Generate\n",
    "    answer = generate_response(query, movies, intent=query_info['intent'])\n",
    "    print(f\"  Answer: {answer[:150]}...\")\n",
    "    print()\n",
    "    \n",
    "    return movies, answer\n",
    "\n",
    "# Test various queries\n",
    "queries = [\n",
    "    \"Tell me about The Matrix\",\n",
    "    \"Recommend comedy movies from 2010\",\n",
    "    \"What are the best sci-fi films?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    test_pipeline(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2b237",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluation Dataset  \n",
    "Construct a small benchmark set of user queries to test the `parse_query` function’s accuracy in identifying intent, genre, and year, then compute overall parsing accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170e00e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Create Evaluation Dataset ===\n",
      "\n",
      "                               query  intent_correct  genre_correct  \\\n",
      "0  Recommend action movies from 2015            True           True   \n",
      "1            Tell me about Inception            True           True   \n",
      "2          What are the best movies?            True           True   \n",
      "3               Show me sci-fi films            True           True   \n",
      "\n",
      "   year_correct  all_correct  \n",
      "0          True         True  \n",
      "1          True         True  \n",
      "2          True         True  \n",
      "3          True         True  \n",
      "\n",
      "Accuracy: 4/4 = 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluation Dataset\n",
    "\n",
    "print(\"=== Create Evaluation Dataset ===\\n\")\n",
    "\n",
    "eval_queries = [\n",
    "    {\n",
    "        \"query\": \"Recommend action movies from 2015\",\n",
    "        \"expected_genre\": \"action\",\n",
    "        \"expected_year\": 2015,\n",
    "        \"expected_intent\": \"recommend\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Tell me about Inception\",\n",
    "        \"expected_keywords\": \"inception\",\n",
    "        \"expected_intent\": \"describe\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are the best movies?\",\n",
    "        \"expected_intent\": \"top_rated\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Show me sci-fi films\",\n",
    "        \"expected_genre\": \"science fiction\",\n",
    "        \"expected_intent\": \"search\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for test in eval_queries:\n",
    "    query = test['query']\n",
    "    parsed = parse_query(query)\n",
    "    \n",
    "    # Check intent\n",
    "    intent_match = parsed['intent'] == test.get('expected_intent')\n",
    "    \n",
    "    # Check genre\n",
    "    genre_match = True\n",
    "    if 'expected_genre' in test:\n",
    "        genre_match = parsed['genre'] == test['expected_genre']\n",
    "    \n",
    "    # Check year\n",
    "    year_match = True\n",
    "    if 'expected_year' in test:\n",
    "        year_match = parsed['year'] == test['expected_year']\n",
    "    \n",
    "    results.append({\n",
    "        'query': query,\n",
    "        'intent_correct': intent_match,\n",
    "        'genre_correct': genre_match,\n",
    "        'year_correct': year_match,\n",
    "        'all_correct': intent_match and genre_match and year_match\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "print(f\"\\nAccuracy: {df['all_correct'].sum()}/{len(df)} = {df['all_correct'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136aa18",
   "metadata": {},
   "source": [
    "### Retrieval Quality Evaluation  \n",
    "Assess how well the database retrieval matches known ground truth movie IDs by checking if expected titles appear in search results and calculating the overall hit rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43abb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Retrieval Quality Evaluation ===\n",
      "\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND title LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%inception%', 5]\n",
      "inception: ✓ - Inception\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND title LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%matrix%', 5]\n",
      "the matrix: ✓ - The Matrix\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 2015, 5]\n",
      "action 2015: ✓ - Baahubali: The Beginning\n",
      "\n",
      "Retrieval Hit Rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Retrieval Quality Evaluation\n",
    "\n",
    "print(\"=== Retrieval Quality Evaluation ===\\n\")\n",
    "\n",
    "# Manual ground truth\n",
    "ground_truth = {\n",
    "    \"inception\": [27205],  # Movie IDs that should be returned\n",
    "    \"the matrix\": [603],\n",
    "    \"action 2015\": [76341, 102899, 177677]  # Any of these\n",
    "}\n",
    "\n",
    "def evaluate_retrieval(query, expected_ids):\n",
    "    parsed = parse_query(query)\n",
    "    movies = db.search(\n",
    "        title=parsed.get('keywords'),\n",
    "        genre=parsed.get('genre'),\n",
    "        year=parsed.get('year'),\n",
    "        limit=5\n",
    "    )\n",
    "    \n",
    "    retrieved_ids = [m['id'] for m in movies]\n",
    "    \n",
    "    # Check if any expected ID is in retrieved\n",
    "    hit = any(eid in retrieved_ids for eid in expected_ids)\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'retrieved': len(movies),\n",
    "        'hit': hit,\n",
    "        'top_result': movies[0]['title'] if movies else None\n",
    "    }\n",
    "\n",
    "retrieval_results = []\n",
    "for query, expected_ids in ground_truth.items():\n",
    "    result = evaluate_retrieval(query, expected_ids)\n",
    "    retrieval_results.append(result)\n",
    "    print(f\"{query}: {'✓' if result['hit'] else '✗'} - {result['top_result']}\")\n",
    "\n",
    "retrieval_df = pd.DataFrame(retrieval_results)\n",
    "print(f\"\\nRetrieval Hit Rate: {retrieval_df['hit'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9ed1c",
   "metadata": {},
   "source": [
    "### Response Quality Check  \n",
    "Evaluate LLM-generated answers for relevance and completeness — verifying that they mention movie titles, genres, ratings, and have reasonable length to assess overall response quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4084664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Response Quality Check ===\n",
      "\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 2015, 3]\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND title LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%matrix%', 1]\n",
      "\n",
      "Query: Recommend action movies from 2015\n",
      "  has_movie_title: ✓\n",
      "  mentions_genre: ✓\n",
      "  has_rating: ✗\n",
      "  length_ok: ✓\n",
      "\n",
      "Query: Tell me about The Matrix\n",
      "  has_movie_title: ✓\n",
      "  mentions_genre: ✓\n",
      "  has_rating: ✓\n",
      "  length_ok: ✓\n",
      "\n",
      "=== Quality Summary ===\n",
      "has_movie_title: 100.0%\n",
      "mentions_genre: 100.0%\n",
      "has_rating: 50.0%\n",
      "length_ok: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Response Quality Check\n",
    "\n",
    "print(\"=== Response Quality Check ===\\n\")\n",
    "\n",
    "def check_response_quality(query, movies):\n",
    "    answer = generate_response(query, movies)\n",
    "    \n",
    "    # Basic checks\n",
    "    checks = {\n",
    "        'has_movie_title': any(m['title'].lower() in answer.lower() for m in movies),\n",
    "        'mentions_genre': any(g.lower() in answer.lower() for m in movies for g in m.get('genres', [])),\n",
    "        'has_rating': any(str(m['vote_average']) in answer for m in movies),\n",
    "        'length_ok': 50 < len(answer) < 500\n",
    "    }\n",
    "    \n",
    "    return checks\n",
    "\n",
    "# Test on a few queries\n",
    "test_cases = [\n",
    "    (\"Recommend action movies from 2015\", db.search(genre=\"action\", year=2015, limit=3)),\n",
    "    (\"Tell me about The Matrix\", db.search(title=\"matrix\", limit=1))\n",
    "]\n",
    "\n",
    "quality_results = []\n",
    "for query, movies in test_cases:\n",
    "    if not movies:\n",
    "        continue\n",
    "    \n",
    "    checks = check_response_quality(query, movies)\n",
    "    checks['query'] = query\n",
    "    quality_results.append(checks)\n",
    "    \n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    for check, passed in checks.items():\n",
    "        if check != 'query':\n",
    "            print(f\"  {check}: {'✓' if passed else '✗'}\")\n",
    "\n",
    "quality_df = pd.DataFrame(quality_results)\n",
    "print(\"\\n=== Quality Summary ===\")\n",
    "for col in quality_df.columns:\n",
    "    if col != 'query':\n",
    "        print(f\"{col}: {quality_df[col].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be6b2b",
   "metadata": {},
   "source": [
    "### Latency Benchmarking  \n",
    "Measure the end-to-end execution time for query parsing, database retrieval, and LLM response generation to evaluate system performance and identify latency bottlenecks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307b2416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Latency Benchmarking ===\n",
      "\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 2015, 5]\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 2015, 5]\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 2015, 5]\n",
      "Query: Recommend action movies from 2015\n",
      "\n",
      "Parse:     0.0ms\n",
      "Search:    2.2ms\n",
      "LLM:       1299.5ms\n",
      "Total:     1301.8ms\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Latency Benchmarking\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"=== Latency Benchmarking ===\\n\")\n",
    "\n",
    "def benchmark_query(query, runs=3):\n",
    "    times = {\n",
    "        'parse': [],\n",
    "        'search': [],\n",
    "        'llm': [],\n",
    "        'total': []\n",
    "    }\n",
    "    \n",
    "    for _ in range(runs):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Parse\n",
    "        t1 = time.time()\n",
    "        parsed = parse_query(query)\n",
    "        times['parse'].append(time.time() - t1)\n",
    "        \n",
    "        # Search\n",
    "        t2 = time.time()\n",
    "        movies = db.search(\n",
    "            title=parsed.get('keywords'),\n",
    "            genre=parsed.get('genre'),\n",
    "            year=parsed.get('year')\n",
    "        )\n",
    "        times['search'].append(time.time() - t2)\n",
    "        \n",
    "        # LLM\n",
    "        t3 = time.time()\n",
    "        answer = generate_response(query, movies, parsed['intent'])\n",
    "        times['llm'].append(time.time() - t3)\n",
    "        \n",
    "        times['total'].append(time.time() - start)\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_times = {k: sum(v)/len(v) for k, v in times.items()}\n",
    "    return avg_times\n",
    "\n",
    "# Benchmark\n",
    "query = \"Recommend action movies from 2015\"\n",
    "results = benchmark_query(query, runs=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Parse:     {results['parse']*1000:.1f}ms\")\n",
    "print(f\"Search:    {results['search']*1000:.1f}ms\")\n",
    "print(f\"LLM:       {results['llm']*1000:.1f}ms\")\n",
    "print(f\"Total:     {results['total']*1000:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78073e2e",
   "metadata": {},
   "source": [
    "### Export Evaluation Results  \n",
    "Aggregate metrics from query parsing, retrieval, response quality, and latency tests, then save the evaluation report as a JSON file for record-keeping and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c98901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Export Evaluation Results ===\n",
      "\n",
      "Results saved to evaluation_results.json\n",
      "\n",
      "=== Summary ===\n",
      "{\n",
      "  \"query_parser_accuracy\": 1.0,\n",
      "  \"retrieval_hit_rate\": 1.0,\n",
      "  \"response_quality\": {\n",
      "    \"has_movie_title\": 1.0,\n",
      "    \"mentions_genre\": 1.0,\n",
      "    \"has_rating\": 0.5,\n",
      "    \"length_ok\": 1.0\n",
      "  },\n",
      "  \"latency_ms\": {\n",
      "    \"parse\": 0.030914942423502602,\n",
      "    \"search\": 2.247492472330729,\n",
      "    \"llm\": 1299.5363076527913,\n",
      "    \"total\": 1301.817258199056\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Export Results\n",
    "\n",
    "print(\"=== Export Evaluation Results ===\\n\")\n",
    "\n",
    "# Combine all results\n",
    "evaluation_report = {\n",
    "    'query_parser_accuracy': df['all_correct'].mean(),\n",
    "    'retrieval_hit_rate': retrieval_df['hit'].mean(),\n",
    "    'response_quality': {\n",
    "        col: quality_df[col].mean() \n",
    "        for col in quality_df.columns if col != 'query'\n",
    "    },\n",
    "    'latency_ms': {\n",
    "        k: v*1000 for k, v in results.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('../evaluation_results.json', 'w') as f:\n",
    "    json.dump(evaluation_report, f, indent=2)\n",
    "\n",
    "print(\"Results saved to evaluation_results.json\")\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(json.dumps(evaluation_report, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e2b67c",
   "metadata": {},
   "source": [
    "### Agent Capability Testing  \n",
    "Evaluate the Agent system’s ability to handle complex analytical queries beyond simple retrieval, recording answers, methods used, and overall agent success rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbd368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent Capability Tests ===\n",
      "\n",
      "\n",
      "Query: Which year had the most movies released?\n",
      "Answer:  \n",
      "\n",
      "The year with the most movies released was 2019.\n",
      "Method: sql_agent\n",
      "\n",
      "Query: What's the average rating of action movies?\n",
      "Answer:  \n",
      "\n",
      "The average rating of action movies is 4.2 out of 5 stars.\n",
      "Method: sql_agent\n",
      "\n",
      "Query: List directors with more than 3 movies\n",
      "Answer:  \n",
      "\n",
      "The result is:\n",
      " \n",
      "Director\n",
      "Name\n",
      "Movie Count\n",
      "Total Rows: 10\n",
      "Method: sql_agent\n",
      "\n",
      "Query: How many movies have rating above 8.5?\n",
      "Answer:  \n",
      "\n",
      "The answer is: 1\n",
      "Method: sql_agent\n",
      "\n",
      "=== Agent Success Rate ===\n",
      "Success: 4/4 = 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Agent Capability Testing\n",
    "\n",
    "print(\"=== Agent Capability Tests ===\\n\")\n",
    "from app.agent_service import query_with_agent\n",
    "# Test complex queries that traditional approach can't handle\n",
    "complex_queries = [\n",
    "    \"Which year had the most movies released?\",\n",
    "    \"What's the average rating of action movies?\",\n",
    "    \"List directors with more than 3 movies\",\n",
    "    \"How many movies have rating above 8.5?\"\n",
    "]\n",
    "\n",
    "agent_results = []\n",
    "\n",
    "for query in complex_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    result = query_with_agent(query)\n",
    "    \n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(f\"Method: {result['method']}\")\n",
    "    \n",
    "    agent_results.append({\n",
    "        'query': query,\n",
    "        'success': result['method'] != 'agent_error',\n",
    "        'answer_length': len(result['answer'])\n",
    "    })\n",
    "\n",
    "agent_df = pd.DataFrame(agent_results)\n",
    "print(f\"\\n=== Agent Success Rate ===\")\n",
    "print(f\"Success: {agent_df['success'].sum()}/{len(agent_df)} = {agent_df['success'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd2df3",
   "metadata": {},
   "source": [
    "### Agent Robustness Testing  \n",
    "Test how the agent handles edge cases, invalid, or unsafe queries, ensuring it fails gracefully without breaking or performing unintended actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa4cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent Robustness Tests ===\n",
      "\n",
      "\n",
      "Query: 'Show me movies from year 3000'\n",
      "  Answer:  \n",
      "\n",
      "The results are empty....\n",
      "\n",
      "Query: 'What is the meaning of life?'\n",
      "  Answer:  \n",
      "\n",
      "The results are empty....\n",
      "\n",
      "Query: 'Delete all movies'\n",
      "  Answer:  \n",
      "\n",
      "The movie table has a column named 'title' and another named 'genre'. The gen...\n",
      "\n",
      "Query: ''\n",
      "  Answer: ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Agent Robustness Testing\n",
    "\n",
    "print(\"=== Agent Robustness Tests ===\\n\")\n",
    "\n",
    "# Edge cases\n",
    "edge_cases = [\n",
    "    \"Show me movies from year 3000\",  # Impossible query\n",
    "    \"What is the meaning of life?\",   # Non-movie query\n",
    "    \"Delete all movies\",              # Dangerous query (should be blocked)\n",
    "    \"\",                               # Empty query\n",
    "]\n",
    "\n",
    "for query in edge_cases:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    result = query_with_agent(query)\n",
    "    \n",
    "    if result['method'] == 'agent_error':\n",
    "        print(f\"  ✓ Handled gracefully: {result['answer']}\")\n",
    "    else:\n",
    "        print(f\"  Answer: {result['answer'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046028f",
   "metadata": {},
   "source": [
    "\n",
    "### Traditional vs Agent — Latency & Accuracy Comparison\n",
    "This section benchmarks both retrieval approaches across representative user queries.  \n",
    "It measures **accuracy** (whether each method handled the query type correctly) and **latency** (average response time).  \n",
    "\n",
    "The traditional approach uses rule-based parsing and SQL templates — ideal for structured lookup queries.  \n",
    "The agentic approach autonomously generates SQL, handling both structured and analytical questions.  \n",
    "\n",
    "We use five mixed query types to evaluate coverage, success, and execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ab97e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRADITIONAL vs AGENT: LATENCY & ACCURACY COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Query: Recommend action movies from 2015\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? AND year = ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%action%', 2015, 5]\n",
      "\n",
      "Query: What are the top rated movies?\n",
      "\n",
      "Query: How many movies are in the database?\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND title LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%how many are database?%', 5]\n",
      "\n",
      "Query: What's the average rating of sci-fi movies?\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND title LIKE ? AND genres LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, \"%'s average rating ?%\", '%science fiction%', 5]\n",
      "\n",
      "Query: Show me comedy movies\n",
      "DEBUG Query: \n",
      "            SELECT id, title, year, genres, overview, \n",
      "                vote_average, vote_count, movie_cast, director\n",
      "            FROM movies \n",
      "            WHERE vote_average >= ?\n",
      "         AND genres LIKE ? ORDER BY vote_average DESC, vote_count DESC LIMIT ?\n",
      "DEBUG Params: [0.0, '%comedy%', 5]\n",
      "\n",
      "Accuracy:\n",
      "  Traditional: 5/5\n",
      "  Agent: 5/5\n",
      "\n",
      "Avg Latency (s):\n",
      "  Traditional: 1.51\n",
      "  Agent: 0.76\n",
      "\n",
      "Results:\n",
      "                                      Query  Traditional_Success  Agent_Success  Traditional_Time  Agent_Time\n",
      "          Recommend action movies from 2015                 True           True              1.69        1.11\n",
      "             What are the top rated movies?                 True           True              1.49        1.05\n",
      "       How many movies are in the database?                False           True               NaN        0.23\n",
      "What's the average rating of sci-fi movies?                False           True               NaN        0.35\n",
      "                      Show me comedy movies                 True           True              1.34        1.05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRADITIONAL vs AGENT: LATENCY & ACCURACY COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_cases = [\n",
    "    (\"Recommend action movies from 2015\", True, True),\n",
    "    (\"What are the top rated movies?\", True, True),\n",
    "    (\"How many movies are in the database?\", False, True),\n",
    "    (\"What's the average rating of sci-fi movies?\", False, True),\n",
    "    (\"Show me comedy movies\", True, True)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for query, can_traditional, can_agent in test_cases:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    row = {\"Query\": query}\n",
    "\n",
    "    # --- Traditional ---\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        q = parse_query(query)\n",
    "        if q[\"intent\"] == \"top_rated\":\n",
    "            movies = db.get_top_rated(limit=5)\n",
    "        else:\n",
    "            movies = db.search(q.get(\"keywords\"), q.get(\"genre\"), q.get(\"year\"), limit=5)\n",
    "        if movies:\n",
    "            generate_response(query, movies, q[\"intent\"])\n",
    "            row[\"Traditional_Time\"] = round(time.time() - t0, 2)\n",
    "            row[\"Traditional_Success\"] = True\n",
    "        else:\n",
    "            raise ValueError(\"No results\")\n",
    "    except Exception:\n",
    "        row[\"Traditional_Time\"] = None\n",
    "        row[\"Traditional_Success\"] = False\n",
    "\n",
    "    # --- Agent ---\n",
    "    try:\n",
    "        t1 = time.time()\n",
    "        res = query_with_agent(query)\n",
    "        if res.get(\"method\") == \"sql_agent\":\n",
    "            row[\"Agent_Time\"] = round(time.time() - t1, 2)\n",
    "            row[\"Agent_Success\"] = True\n",
    "        else:\n",
    "            raise ValueError(\"Invalid method\")\n",
    "    except Exception:\n",
    "        row[\"Agent_Time\"] = None\n",
    "        row[\"Agent_Success\"] = False\n",
    "\n",
    "    # Accuracy check\n",
    "    row[\"Traditional_Correct\"] = row[\"Traditional_Success\"] == can_traditional\n",
    "    row[\"Agent_Correct\"] = row[\"Agent_Success\"] == can_agent\n",
    "    results.append(row)\n",
    "\n",
    "# --- Summary ---\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nAccuracy:\")\n",
    "print(f\"  Traditional: {df['Traditional_Correct'].sum()}/{len(df)}\")\n",
    "print(f\"  Agent: {df['Agent_Correct'].sum()}/{len(df)}\")\n",
    "\n",
    "print(\"\\nAvg Latency (s):\")\n",
    "t_ok = df[df[\"Traditional_Success\"]][\"Traditional_Time\"].dropna()\n",
    "a_ok = df[df[\"Agent_Success\"]][\"Agent_Time\"].dropna()\n",
    "if len(t_ok): print(f\"  Traditional: {t_ok.mean():.2f}\")\n",
    "if len(a_ok): print(f\"  Agent: {a_ok.mean():.2f}\")\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(df[[\"Query\", \"Traditional_Success\", \"Agent_Success\", \"Traditional_Time\", \"Agent_Time\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a453d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **Setup & Initialization**  \n",
    "   - Imported required modules, verified the SQLite database (`movies.db`) exists, and initialized a `MovieDB` connection.\n",
    "\n",
    "2. **Database Query Tests**  \n",
    "   - Validated search functionality by title, genre, year, combined filters, and top-rated movies.\n",
    "\n",
    "3. **Query Processing**  \n",
    "   - Tested `parse_query` for extracting intent, genre, year, and keywords from natural language queries.\n",
    "\n",
    "4. **LLM Response Generation**  \n",
    "   - Verified `generate_response` produces coherent, context-aware recommendations based on retrieved movies.\n",
    "\n",
    "5. **End-to-End Pipeline**  \n",
    "   - Combined parsing, database search, and LLM response generation to confirm workflow integration.\n",
    "\n",
    "6. **Evaluation Dataset**  \n",
    "   - Benchmarked query parser accuracy using predefined test queries for intent, genre, and year extraction.\n",
    "\n",
    "7. **Retrieval Quality Evaluation**  \n",
    "   - Assessed database search performance against ground truth movie IDs, calculating hit rates.\n",
    "\n",
    "8. **Response Quality Check**  \n",
    "   - Ensured LLM answers included relevant movie titles, genres, ratings, and were of reasonable length.\n",
    "\n",
    "9. **Latency Benchmarking**  \n",
    "   - Measured execution times for parsing, search, LLM response, and full end-to-end queries.\n",
    "\n",
    "10. **Export Evaluation Results**  \n",
    "    - Aggregated metrics from parsing, retrieval, response quality, and latency tests into a JSON report.\n",
    "\n",
    "11. **Agent Capability Testing**  \n",
    "    - Evaluated handling of complex analytical queries, capturing answers, methods, and success rate.\n",
    "\n",
    "12. **Agent Robustness Testing**  \n",
    "    - Tested edge cases and invalid queries to ensure the agent fails gracefully and safely.\n",
    "\n",
    "12. **Traditional vs Agent — Latency & Accuracy Comparison** \n",
    "\n",
    "    - Compared traditional retrieval and agentic RAG for speed, accuracy, and coverage, highlighting trade-offs and hybrid usage.\n",
    "\n",
    "Overall, the notebook provides a structured approach to building, testing, and benchmarking a hybrid movie recommendation system that integrates both database-backed retrieval and LLM-based response generation, demonstrating both traditional and agentic RAG workflows in a safe and measurable way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
